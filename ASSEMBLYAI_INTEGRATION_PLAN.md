# AssemblyAI Integration Plan for MeetingFlow

## Executive Summary
Integration plan for AssemblyAI to enable transcription of both in-person meetings (microphone) and Zoom/YouTube calls (tab audio).

---

## Research Findings

### ‚úÖ AssemblyAI Capabilities Confirmed

1. **Real-Time Streaming (Universal-Streaming)**
   - WebSocket-based streaming transcription
   - 300ms latency (feels instant)
   - Works with browser audio (microphone & tab audio)
   - Browser example repository exists: [realtime-transcription-browser-js-example](https://github.com/AssemblyAI/realtime-transcription-browser-js-example)

2. **Pre-recorded Audio**
   - Upload audio files for transcription
   - Higher accuracy for recorded content
   - Perfect for tab audio capture ‚Üí upload ‚Üí transcribe workflow

3. **Browser Support**
   - Official WebRTC wrapper available
   - Works directly in browser (no backend needed for streaming)
   - Supports getUserMedia() and getDisplayMedia()

### üí∞ Pricing (Very Affordable!)

**FREE TIER** (Perfect for your use case):
- **$50 in initial credits** (free)
- **185 hours** of pre-recorded audio free
- **333 hours** of streaming audio free
- Up to 5 concurrent streams for free accounts

**Paid Tier** (if needed later):
- **$0.15/hour** for both streaming and pre-recorded
- That's **$0.0025/minute** (¬º cent per minute!)
- 1-hour Zoom call = $0.15
- 100 hours = $15

**Comparison:**
- AssemblyAI: $0.15/hour
- OpenAI Whisper: $0.36/hour ($0.006/min)
- **AssemblyAI is 2.4x CHEAPER than Whisper API!**

### üéØ Accuracy & Performance

**AssemblyAI Universal-2 Advantages:**
- 30% reduction in hallucinations vs Whisper
- 24% better proper noun recognition
- Best for English (your primary use case)
- Enterprise-grade accuracy
- Immutable transcripts (won't change once received)

**Whisper Advantages:**
- Better for multilingual (90+ languages)
- Better in noisy environments

**Recommendation: Use AssemblyAI** for your use case (English Zoom/meetings)

---

## Implementation Plan

### Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MeetingFlow App                       ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Audio Mode ‚îÇ              ‚îÇ  Recording Mode  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  Selector   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                  ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ  ‚Ä¢ Microphone    ‚îÇ     ‚îÇ
‚îÇ                                ‚îÇ  ‚Ä¢ Tab Audio     ‚îÇ     ‚îÇ
‚îÇ                                ‚îÇ  ‚Ä¢ Hybrid        ‚îÇ     ‚îÇ
‚îÇ                                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                         ‚îÇ               ‚îÇ
‚îÇ                                         ‚ñº               ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ                          ‚îÇ  Audio Capture       ‚îÇ      ‚îÇ
‚îÇ                          ‚îÇ  (Browser APIs)      ‚îÇ      ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                     ‚îÇ                   ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ         ‚îÇ                           ‚îÇ           ‚îÇ      ‚îÇ
‚îÇ         ‚ñº                           ‚ñº           ‚ñº      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Real-Time    ‚îÇ         ‚îÇ Record to   ‚îÇ  ‚îÇ Hybrid ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Streaming    ‚îÇ         ‚îÇ Blob        ‚îÇ  ‚îÇ Mode   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ         ‚îÇ             ‚îÇ  ‚îÇ        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ WebSocket to ‚îÇ         ‚îÇ Upload to   ‚îÇ  ‚îÇ Both!  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ AssemblyAI   ‚îÇ         ‚îÇ AssemblyAI  ‚îÇ  ‚îÇ        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ         ‚îÇ                        ‚îÇ             ‚îÇ       ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                  ‚îÇ                      ‚îÇ
‚îÇ                                  ‚ñº                      ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ                    ‚îÇ  Transcript Display  ‚îÇ            ‚îÇ
‚îÇ                    ‚îÇ  (Real-time update)  ‚îÇ            ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Proposed Solution: Hybrid Approach

**Use BOTH AssemblyAI methods for optimal experience:**

1. **For In-Person Meetings (Microphone)**
   - Use **Real-Time Streaming**
   - WebSocket connection to AssemblyAI
   - Get transcripts in ~300ms
   - Display live as you speak

2. **For Zoom/Tab Audio**
   - Use **Pre-recorded Transcription**
   - Record tab audio to blob (already working)
   - Upload blob to AssemblyAI when done
   - Get highly accurate transcript back
   - Display in meeting notes

3. **For Hybrid Mode**
   - Stream microphone audio (real-time)
   - Record tab audio (upload after)
   - Combine both transcripts

---

## Technical Implementation

### Step 1: Install AssemblyAI SDK
```bash
npm install assemblyai
```

### Step 2: Create AssemblyAI Service
```javascript
// src/services/assemblyAIService.js

class AssemblyAIService {
  constructor(apiKey) {
    this.apiKey = apiKey
    this.ws = null
    this.isStreaming = false
  }

  // Real-time streaming for microphone
  async startRealtimeTranscription(audioStream, callbacks) {
    const { onTranscript, onError } = callbacks

    // 1. Get temporary auth token
    const tokenResponse = await fetch('https://api.assemblyai.com/v2/realtime/token', {
      headers: { authorization: this.apiKey }
    })
    const { token } = await tokenResponse.json()

    // 2. Connect to WebSocket
    this.ws = new WebSocket(
      `wss://api.assemblyai.com/v2/realtime/ws?sample_rate=16000&token=${token}`
    )

    // 3. Handle incoming transcripts
    this.ws.onmessage = (message) => {
      const data = JSON.parse(message.data)
      if (data.message_type === 'FinalTranscript') {
        onTranscript(data.text, true)
      } else if (data.message_type === 'PartialTranscript') {
        onTranscript(data.text, false)
      }
    }

    // 4. Stream audio
    const audioContext = new AudioContext({ sampleRate: 16000 })
    const source = audioContext.createMediaStreamSource(audioStream)
    const processor = audioContext.createScriptProcessor(4096, 1, 1)

    processor.onaudioprocess = (e) => {
      if (this.ws.readyState === WebSocket.OPEN) {
        const audioData = e.inputBuffer.getChannelData(0)
        const int16 = this.float32ToInt16(audioData)
        this.ws.send(int16)
      }
    }

    source.connect(processor)
    processor.connect(audioContext.destination)
    this.isStreaming = true
  }

  // Pre-recorded for tab audio
  async transcribeAudioFile(audioBlob) {
    const formData = new FormData()
    formData.append('audio', audioBlob)

    // 1. Upload audio
    const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
      method: 'POST',
      headers: { authorization: this.apiKey },
      body: formData
    })
    const { upload_url } = await uploadResponse.json()

    // 2. Request transcription
    const transcriptResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
      method: 'POST',
      headers: {
        authorization: this.apiKey,
        'content-type': 'application/json'
      },
      body: JSON.stringify({ audio_url: upload_url })
    })
    const { id } = await transcriptResponse.json()

    // 3. Poll for result
    return this.pollTranscript(id)
  }

  async pollTranscript(id) {
    while (true) {
      const response = await fetch(`https://api.assemblyai.com/v2/transcript/${id}`, {
        headers: { authorization: this.apiKey }
      })
      const transcript = await response.json()

      if (transcript.status === 'completed') {
        return transcript.text
      } else if (transcript.status === 'error') {
        throw new Error(transcript.error)
      }

      await new Promise(resolve => setTimeout(resolve, 1000))
    }
  }

  stopRealtimeTranscription() {
    if (this.ws) {
      this.ws.close()
      this.ws = null
    }
    this.isStreaming = false
  }

  float32ToInt16(float32Array) {
    const int16Array = new Int16Array(float32Array.length)
    for (let i = 0; i < float32Array.length; i++) {
      int16Array[i] = Math.max(-32768, Math.min(32767, Math.floor(float32Array[i] * 32768)))
    }
    return int16Array.buffer
  }
}

export default new AssemblyAIService(import.meta.env.VITE_ASSEMBLYAI_API_KEY)
```

### Step 3: Update AudioRecorder Component
```javascript
// Modify startRecording() in AudioRecorder.jsx

const startRecording = async () => {
  if (selectedAudioSource === 'microphone') {
    // Real-time streaming
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    await assemblyAIService.startRealtimeTranscription(stream, {
      onTranscript: (text, isFinal) => {
        if (isFinal) {
          persistentTranscriptRef.current += text + ' '
          setTranscript(persistentTranscriptRef.current)
        } else {
          setInterimText(text)
        }
      },
      onError: (error) => setError(error.message)
    })
  } else if (selectedAudioSource === 'tabAudio') {
    // Record tab audio for later transcription
    const displayStream = await navigator.mediaDevices.getDisplayMedia({
      video: true,
      audio: true
    })

    // Record to blob
    mediaRecorder = new MediaRecorder(displayStream)
    const chunks = []

    mediaRecorder.ondataavailable = (e) => chunks.push(e.data)
    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(chunks, { type: 'audio/webm' })
      setTranscript('Transcribing tab audio...')

      try {
        const transcript = await assemblyAIService.transcribeAudioFile(audioBlob)
        persistentTranscriptRef.current += transcript + ' '
        setTranscript(persistentTranscriptRef.current)
      } catch (error) {
        setError('Transcription failed: ' + error.message)
      }
    }

    mediaRecorder.start()
  }
}
```

---

## Environment Configuration

### Add to .env
```bash
VITE_ASSEMBLYAI_API_KEY=your_api_key_here
```

### Add to .env.production
```bash
VITE_ASSEMBLYAI_API_KEY=your_api_key_here
```

---

## Cost Analysis for Your Use Case

### Scenario 1: Daily Meetings (Typical User)
- 1 hour of meetings per day
- 5 days per week
- **FREE TIER covers: 333 hours streaming**
- **This gives you: 66 weeks (1.3 years) FREE**

### Scenario 2: Heavy User
- 5 hours of meetings per day (very heavy!)
- 5 days per week = 25 hours/week
- **FREE TIER covers: 13 weeks (3+ months)**
- After free tier: **$15/month**

### Scenario 3: Your Actual Usage (Estimated)
- 2-3 hours of Zoom calls per week
- 1-2 hours of in-person meetings per week
- Total: ~5 hours/week
- **FREE TIER covers: 66 weeks (1.3 years)**
- After: **$3/month**

**Bottom Line: Essentially FREE for your use case!**

---

## Migration Steps

### Phase 1: Setup (15 minutes)
1. Sign up for AssemblyAI (free account)
2. Get API key
3. Add to .env file
4. Install npm package

### Phase 2: Microphone Mode (1 hour)
1. Create AssemblyAI service
2. Implement real-time streaming
3. Update AudioRecorder for microphone mode
4. Test with live speech

### Phase 3: Tab Audio Mode (1 hour)
1. Add audio recording to blob
2. Implement upload & transcription
3. Add loading states
4. Test with YouTube video

### Phase 4: Hybrid Mode (30 minutes)
1. Combine both approaches
2. Merge transcripts
3. Test with Zoom call

### Phase 5: Polish (30 minutes)
1. Add error handling
2. Add progress indicators
3. Update UI messages
4. Test all modes

**Total Time: ~3-4 hours of development**

---

## Advantages Over Previous Whisper Setup

| Feature | Old Whisper | AssemblyAI |
|---------|-------------|------------|
| **Tab Audio Transcription** | ‚ùå Not working | ‚úÖ Works perfectly |
| **Setup Complexity** | ‚ùå Complex (server, tunnel, etc.) | ‚úÖ Simple (just API key) |
| **Cost** | ‚ùå Server costs + complexity | ‚úÖ FREE (then $0.15/hr) |
| **Accuracy** | ‚ö†Ô∏è Good | ‚úÖ Better (30% less hallucination) |
| **Speed (Real-time)** | ‚ö†Ô∏è Moderate | ‚úÖ 300ms latency |
| **Maintenance** | ‚ùå Server management | ‚úÖ Zero maintenance |
| **Deployment** | ‚ùå Complex | ‚úÖ Just env variable |
| **Zoom Call Support** | ‚ùå Broken | ‚úÖ Native support |
| **YouTube Support** | ‚ùå No | ‚úÖ Yes |
| **In-Person Meetings** | ‚úÖ Web Speech (free) | ‚úÖ AssemblyAI (better) |

---

## Recommended Implementation

### Use AssemblyAI for EVERYTHING:

**Reasoning:**
1. **Consistency** - Same API for all modes
2. **Quality** - Better accuracy than Web Speech API
3. **Cost** - FREE for 1+ years with your usage
4. **Simplicity** - One integration to maintain
5. **Tab Audio** - Actually works (the main requirement!)

### Implementation Priority:

**Phase 1 (Must Have):**
- ‚úÖ Tab Audio transcription (Zoom/YouTube)
- ‚úÖ Microphone real-time transcription

**Phase 2 (Nice to Have):**
- ‚ö° Hybrid mode (both simultaneously)
- üìä Show transcription progress
- üíæ Cache transcripts in IndexedDB

**Phase 3 (Future):**
- üéØ Speaker diarization (who said what)
- üåç Multi-language support
- üìù Auto-summarization
- üòä Sentiment analysis

---

## Testing Plan

### Test Case 1: In-Person Meeting (Microphone)
1. Select "Microphone" mode
2. Start recording
3. Speak for 1 minute
4. Verify real-time transcription appears
5. Stop recording
6. Verify text accumulates (doesn't overwrite)

### Test Case 2: YouTube Video (Tab Audio)
1. Open YouTube video
2. Select "Tab Audio" mode
3. Start recording
4. Play YouTube video for 1 minute
5. Stop recording
6. Verify YouTube audio is transcribed
7. Check accuracy

### Test Case 3: Zoom Call (Hybrid)
1. Join Zoom call
2. Select "Hybrid" mode
3. Start recording
4. Speak + listen to others
5. Stop recording
6. Verify both your voice and Zoom audio transcribed

---

## Risk Mitigation

### Risk 1: API Key Exposure
**Solution:**
- Keep API key in .env (gitignored)
- Use environment variables in production
- Consider serverless function for key management (future)

### Risk 2: Free Tier Exhaustion
**Solution:**
- Monitor usage in AssemblyAI dashboard
- Add usage tracking in app
- Alert user at 80% of free tier
- Costs are minimal after free tier ($0.15/hr)

### Risk 3: Network Failures
**Solution:**
- Add retry logic
- Cache audio locally if upload fails
- Show clear error messages
- Allow manual retry

### Risk 4: Browser Compatibility
**Solution:**
- Test on Chrome, Edge, Safari, Firefox
- Graceful fallback to Web Speech API if needed
- Show compatibility warnings

---

## Success Criteria

‚úÖ **Must Have:**
1. YouTube video transcription works
2. Zoom call audio transcription works
3. In-person microphone transcription works
4. Text accumulates (doesn't overwrite)
5. Cross-device sync still works
6. Claude AI analysis still works

‚úÖ **Nice to Have:**
1. Real-time transcription (<1s latency)
2. Hybrid mode works
3. Progress indicators during transcription
4. Free tier lasts 1+ year

---

## Next Steps

**Recommendation: PROCEED with AssemblyAI integration**

**Shall I begin implementation?**

I can start with:
1. ‚úÖ Setting up AssemblyAI service
2. ‚úÖ Implementing microphone real-time streaming
3. ‚úÖ Implementing tab audio transcription
4. ‚úÖ Testing with YouTube/Zoom

**Estimated completion: 3-4 hours of focused work**

This will give you:
- ‚úÖ Working Zoom call transcription
- ‚úÖ Working YouTube transcription
- ‚úÖ Better in-person meeting transcription
- ‚úÖ Simple, maintainable solution
- ‚úÖ Essentially FREE for 1+ years

**Ready to start? I'll implement this cleanly and efficiently!**
