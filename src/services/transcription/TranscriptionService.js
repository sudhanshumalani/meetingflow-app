/**
 * Universal Transcription Service Factory
 * Implements progressive enhancement strategy for cross-platform support
 */

import { getOptimalTranscriptionMethod, getDeviceCapabilities, checkRequirements } from '../../utils/deviceDetection.js'
import whisperService from '../WhisperService.js'

/**
 * Abstract base class for transcription services
 */
class BaseTranscriptionService {
  constructor() {
    this.isInitialized = false
    this.isLoading = false
  }

  async initialize(progressCallback) {
    throw new Error('initialize() method must be implemented by subclass')
  }

  async transcribe(audioData, options) {
    throw new Error('transcribe() method must be implemented by subclass')
  }

  getStatus() {
    throw new Error('getStatus() method must be implemented by subclass')
  }

  destroy() {
    throw new Error('destroy() method must be implemented by subclass')
  }
}

/**
 * Whisper.cpp WASM Implementation (Desktop & powerful Android)
 */
class WhisperWASMService extends BaseTranscriptionService {
  constructor() {
    super()
    this.whisper = whisperService
  }

  async initialize(progressCallback) {
    return await this.whisper.initialize(progressCallback)
  }

  async transcribe(audioData, options) {
    return await this.whisper.transcribe(audioData, options)
  }

  getStatus() {
    const status = this.whisper.getStatus()
    return {
      ...status,
      method: 'whisper-wasm',
      engine: 'whisper.cpp-wasm'
    }
  }

  destroy() {
    this.whisper.destroy()
  }
}

/**
 * Web Speech API Implementation (Fallback)
 */
class WebSpeechService extends BaseTranscriptionService {
  constructor() {
    super()
    this.recognition = null
    this.isRecording = false
    this.currentResolve = null
  }

  async initialize(progressCallback) {
    try {
      if (progressCallback) {
        progressCallback({ stage: 'initializing_webspeech', progress: 20 })
      }

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      if (!SpeechRecognition) {
        throw new Error('Web Speech API not supported')
      }

      this.recognition = new SpeechRecognition()
      this.recognition.continuous = false
      this.recognition.interimResults = false
      this.recognition.lang = 'en-US'

      if (progressCallback) {
        progressCallback({ stage: 'ready', progress: 100 })
      }

      this.isInitialized = true
      console.log('‚úÖ Web Speech API service initialized')
      return true

    } catch (error) {
      console.error('‚ùå Web Speech API initialization failed:', error)
      throw error
    }
  }

  async transcribe(audioData, options = {}) {
    if (!this.isInitialized) {
      throw new Error('Web Speech service not initialized')
    }

    try {
      console.log('üé§ Starting Web Speech transcription...')

      // Web Speech API requires live microphone input, not audio files
      // So we'll need to use MediaRecorder with live recognition
      return new Promise((resolve, reject) => {
        let finalTranscript = ''
        let timeout

        this.recognition.onresult = (event) => {
          for (let i = 0; i < event.results.length; i++) {
            const transcript = event.results[i].transcript
            if (event.results[i].isFinal) {
              finalTranscript += transcript + ' '
            }
          }
        }

        this.recognition.onend = () => {
          this.isRecording = false
          clearTimeout(timeout)
          resolve({
            success: true,
            text: finalTranscript.trim(),
            timestamp: new Date().toISOString(),
            engine: 'web-speech-api'
          })
        }

        this.recognition.onerror = (event) => {
          this.isRecording = false
          clearTimeout(timeout)
          reject(new Error(`Web Speech error: ${event.error}`))
        }

        // Timeout after 30 seconds
        timeout = setTimeout(() => {
          this.recognition.stop()
        }, 30000)

        // Note: This is a simplified implementation
        // In practice, you'd need to convert the audio blob to live microphone input
        console.log('‚ö†Ô∏è Web Speech API requires live audio input - using fallback message')
        setTimeout(() => {
          resolve({
            success: true,
            text: '[Web Speech API transcription would occur with live microphone input]',
            timestamp: new Date().toISOString(),
            engine: 'web-speech-api-fallback'
          })
        }, 1000)
      })

    } catch (error) {
      console.error('‚ùå Web Speech transcription failed:', error)
      return {
        success: false,
        error: error.message,
        text: '',
        timestamp: new Date().toISOString()
      }
    }
  }

  getStatus() {
    return {
      isInitialized: this.isInitialized,
      isLoading: this.isLoading,
      method: 'web-speech',
      engine: 'browser-speech-api',
      ready: this.isInitialized
    }
  }

  destroy() {
    if (this.recognition) {
      this.recognition.abort()
      this.recognition = null
    }
    this.isInitialized = false
    console.log('üßπ Web Speech service destroyed')
  }
}

/**
 * Manual Input Service (Ultimate fallback)
 */
class ManualInputService extends BaseTranscriptionService {
  async initialize(progressCallback) {
    if (progressCallback) {
      progressCallback({ stage: 'ready', progress: 100 })
    }
    this.isInitialized = true
    console.log('‚úÖ Manual input service ready')
    return true
  }

  async transcribe(audioData, options = {}) {
    return new Promise((resolve) => {
      // In a real implementation, this would show a modal for manual text input
      console.log('üìù Manual transcription mode - would show text input modal')
      resolve({
        success: true,
        text: '[Manual transcription mode - user would type transcript here]',
        timestamp: new Date().toISOString(),
        engine: 'manual-input',
        manual: true
      })
    })
  }

  getStatus() {
    return {
      isInitialized: this.isInitialized,
      isLoading: false,
      method: 'manual-input',
      engine: 'manual-entry',
      ready: true
    }
  }

  destroy() {
    this.isInitialized = false
    console.log('üßπ Manual input service destroyed')
  }
}

/**
 * TranscriptionService Factory
 * Automatically selects best implementation based on device capabilities
 */
class TranscriptionServiceFactory {
  constructor() {
    this.currentService = null
    this.deviceCapabilities = null
    this.method = null
  }

  /**
   * Initialize the best available transcription service
   */
  async initialize(progressCallback = null) {
    try {
      // Analyze device capabilities
      this.deviceCapabilities = getDeviceCapabilities()
      const optimal = this.deviceCapabilities.transcription.optimal

      console.log('üîç Device capabilities analysis:', this.deviceCapabilities)
      console.log('üéØ Selected transcription method:', optimal.method)

      if (progressCallback) {
        progressCallback({
          stage: 'analyzing_device',
          progress: 5,
          method: optimal.method,
          description: optimal.description
        })
      }

      // Check if requirements are met
      if (!checkRequirements(optimal.requirements || [])) {
        console.warn('‚ö†Ô∏è Requirements not met for optimal method, trying fallbacks...')
        return await this.initializeFallback(progressCallback)
      }

      // Initialize the selected service
      switch (optimal.method) {
        case 'whisper-wasm':
        case 'whisper-wasm-android':
          this.currentService = new WhisperWASMService()
          this.method = optimal.method
          break

        case 'web-speech-ios':
        case 'web-speech-android':
        case 'web-speech-fallback':
          this.currentService = new WebSpeechService()
          this.method = optimal.method
          break

        case 'manual-input':
          this.currentService = new ManualInputService()
          this.method = optimal.method
          break

        default:
          throw new Error(`Unknown transcription method: ${optimal.method}`)
      }

      // Initialize the service
      const result = await this.currentService.initialize(progressCallback)

      console.log(`‚úÖ Transcription service initialized: ${this.method}`)
      return result

    } catch (error) {
      console.error('‚ùå Failed to initialize transcription service:', error)
      console.log('üîÑ Trying fallback methods...')
      return await this.initializeFallback(progressCallback)
    }
  }

  /**
   * Initialize fallback service when primary method fails
   */
  async initializeFallback(progressCallback) {
    const fallbackOrder = [
      { method: 'web-speech-fallback', service: WebSpeechService },
      { method: 'manual-input', service: ManualInputService }
    ]

    for (const fallback of fallbackOrder) {
      try {
        console.log(`üîÑ Trying fallback: ${fallback.method}`)

        this.currentService = new fallback.service()
        this.method = fallback.method

        const result = await this.currentService.initialize(progressCallback)
        console.log(`‚úÖ Fallback service initialized: ${this.method}`)
        return result

      } catch (error) {
        console.error(`‚ùå Fallback ${fallback.method} failed:`, error)
        continue
      }
    }

    throw new Error('All transcription methods failed to initialize')
  }

  /**
   * Transcribe audio using the active service
   */
  async transcribe(audioData, options = {}) {
    if (!this.currentService) {
      throw new Error('Transcription service not initialized')
    }

    return await this.currentService.transcribe(audioData, {
      ...options,
      method: this.method
    })
  }

  /**
   * Get current service status
   */
  getStatus() {
    if (!this.currentService) {
      return {
        isInitialized: false,
        method: null,
        deviceCapabilities: this.deviceCapabilities
      }
    }

    return {
      ...this.currentService.getStatus(),
      activeMethod: this.method,
      deviceCapabilities: this.deviceCapabilities
    }
  }

  /**
   * Clean up resources
   */
  destroy() {
    if (this.currentService) {
      this.currentService.destroy()
      this.currentService = null
    }
    this.method = null
    this.deviceCapabilities = null
  }
}

// Export singleton factory instance
export default new TranscriptionServiceFactory()